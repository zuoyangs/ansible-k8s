---
- name: "Install dependency"
  yum:
    name: "{{ item.line }}"
    state: installed
  with_items:
    - {line: 'libnetfilter_cthelper'}
    - {line: 'libnetfilter_cttimeout'}
    - {line: 'libnetfilter_queue'}
    - {line: 'conntrack-tools'}
    - {line: 'ipvsadm'}
    - {line: 'ipset'}
    - {line: 'socat'}

- name: "Create kubernetes directory"
  file:
    path: "{{ item.line }}"
    owner: root
    group: root
    mode: 0755
    state: directory
  with_items:
    - {line: '/etc/kubernetes/pki'}
    - {line: '/etc/kubernetes/manifests'}
    - {line: "{{ kubernetes.kubelet_dir }}"}

- name: "copy kubelet/kube-proxy master/worker node"
  copy:
    src: "{{ item.line }}"
    dest: /usr/bin/
    owner: root
    group: root
    mode: 0750
  with_items:
    - { line: "/tmp/kubernetes-server-{{ kubernetes.version }}-linux/kubernetes/server/bin/kubelet"}
    - { line: "/tmp/kubernetes-server-{{ kubernetes.version }}-linux/kubernetes/server/bin/kubectl"}
    - { line: "/tmp/kubernetes-server-{{ kubernetes.version }}-linux/kubernetes/server/bin/kube-proxy"}

- name: "Distribution worker certs"
  copy:
    src: "{{ item.line }}"
    dest: "/etc/kubernetes/pki/"
    owner: root
    group: root
    mode: 0644
  with_items:
    - {line: "{{ cert.dir }}/ca.pem"}
    - {line: "{{ cert.dir }}/ca.key"}
    - {line: "{{ cert.dir }}/{{ ansible_default_ipv4.address }}/kube-proxy.pem"}
    - {line: "{{ cert.dir }}/{{ ansible_default_ipv4.address }}/kube-proxy.key"}
    - {line: "{{ cert.dir }}/token"}

- name: "Get bootstrap-token"
  copy:
    src: "{{ cert.dir }}/token"
    dest: "/etc/kubernetes/pki/"
    owner: root
    group: root
    mode: 0640

- name: "Get bootstrap-token-id"
  shell: cat /etc/kubernetes/pki/token | grep -v "^#" | awk -F '.' '{print $1}'
  register: token_id

- name: "Get bootstrap-token-secret"
  shell: cat /etc/kubernetes/pki/token | grep -v "^#" | awk -F '.' '{print $2}'
  register: token_secret

- name: "Distribution worker kubeconfig"
  template:
    src: "{{ item.src }}"
    owner: root
    group: root
    mode: 0640
    dest: "{{ item.dest }}"
  with_items:
    - {src: "bootstrap.kubeconfig.j2",dest: "/etc/kubernetes/bootstrap.kubeconfig" }
    - {src: "proxy.kubeconfig.j2",dest: "/etc/kubernetes/proxy.kubeconfig" }

- name: "Distribution worker config"
  template:
    src: "{{ item.src }}"
    owner: root
    group: root
    mode: 0640
    dest: "{{ item.dest }}"
  with_items:
    - {src: "kubelet.conf.j2",dest: "/etc/kubernetes/kubelet.conf" }
    - {src: "10-kubelet.conf.j2",dest: "/etc/sysconfig/kubelet" }
    - {src: "kube-proxy.conf.j2",dest: "/etc/kubernetes/kube-proxy.conf" }

- name: "Distribution worker system unit"
  template:
    src: "{{ item.src }}"
    owner: root
    group: root
    mode: 0644
    dest: "{{ item.dest }}"
  with_items:
    - {src: "kubelet.service.j2",dest: "/usr/lib/systemd/system/kubelet.service" }
    - {src: "kube-proxy.service.j2",dest: "/usr/lib/systemd/system/kube-proxy.service" }

- name: "Check if bootstrap-token exists"
  shell: kubectl -n kube-system get secret bootstrap-token-{{ token_id.stdout }}
  ignore_errors: yes
  delegate_to: "{{ groups['master'][0] }}"
  run_once: true
  register: bootstrap_token_ready

- name: "Create bootstrap-token secret"
  when: bootstrap_token_ready.rc != 0
  shell: kubectl -n kube-system create secret generic bootstrap-token-{{ token_id.stdout }} --type 'bootstrap.kubernetes.io/token' --from-literal description="cluster bootstrap token" --from-literal token-id={{ token_id.stdout }} --from-literal token-secret={{ token_secret.stdout }} --from-literal usage-bootstrap-authentication=true --from-literal usage-bootstrap-signing=true
  delegate_to: "{{ groups['master'][0] }}"
  run_once: true

- name: "Check if clusterrolebinding kubelet-bootstrap exists"
  shell: kubectl get clusterrolebinding kubelet-bootstrap
  ignore_errors: yes
  delegate_to: "{{ groups['master'][0] }}"
  run_once: true
  register: kubelet_bootstrap_ready

- name: "Create clusterrolebinding kubelet-bootstrap"
  when: kubelet_bootstrap_ready.rc != 0
  shell: kubectl create clusterrolebinding kubelet-bootstrap --clusterrole=system:node-bootstrapper --group=system:bootstrappers
  delegate_to: "{{ groups['master'][0] }}"
  run_once: true

- name: "Check if node-autoapprove-bootstrap exists"
  shell: kubectl get clusterrolebinding node-autoapprove-bootstrap
  ignore_errors: yes
  delegate_to: "{{ groups['master'][0] }}"
  run_once: true
  register: node_autoapprove_bootstrap_ready

- name: "Create clusterrolebinding node-autoapprove-bootstrap"
  when: node_autoapprove_bootstrap_ready.rc != 0
  shell: kubectl create clusterrolebinding node-autoapprove-bootstrap --clusterrole=system:certificates.k8s.io:certificatesigningrequests:nodeclient --group=system:bootstrappers
  delegate_to: "{{ groups['master'][0] }}"
  run_once: true

- name: "Check if clusterrolebinding node-autoapprove-certificate-rotation exists"
  shell: kubectl get clusterrolebinding node-autoapprove-certificate-rotation
  ignore_errors: yes
  delegate_to: "{{ groups['master'][0] }}"
  run_once: true
  register: node_autoapprove_certificate_rotation_ready

- name: "Create clusterrolebinding node-autoapprove-certificate-rotation"
  when: node_autoapprove_certificate_rotation_ready.rc != 0
  shell: kubectl create clusterrolebinding node-autoapprove-certificate-rotation --clusterrole=system:certificates.k8s.io:certificatesigningrequests:selfnodeclient --group=system:nodes
  delegate_to: "{{ groups['master'][0] }}"
  run_once: true

- name: "Delete bootstrap-token"
  file:
    path: "/etc/kubernetes/pki/token"
    state: absent

- name: "Restart kubelet"
  systemd:
    name: kubelet
    state: restarted
    daemon_reload: yes
    enabled: yes

- name: "Waiting kubelet starting"
  wait_for:
    host: "{{ ansible_default_ipv4.address }}"
    port: 10250
    delay: 5
    sleep: 2

- name: "kubelet health check"
  uri:
    url: "http://{{ ansible_default_ipv4.address }}:10248/healthz"
    return_content: yes
    validate_certs: no
  register: kubelet
  failed_when: "'ok' not in kubelet.content"
  connection: local

- name: "Restart kube-proxy"
  systemd:
    name: kube-proxy
    state: restarted
    daemon_reload: yes
    enabled: yes

- name: "Waiting kube-proxy starting"
  wait_for:
    host: "{{ ansible_default_ipv4.address }}"
    port: 10256
    delay: 5
    sleep: 2

- name: "kube-proxy health check"
  uri:
    url: "http://{{ ansible_default_ipv4.address }}:10256/healthz"
    return_content: yes
    validate_certs: no
    status_code: 200
  register: proxy
  connection: local

- name: "Create taint for master"
  shell: "kubectl taint nodes {{ hostvars[item].hostname }}-{{ item }} node-role.kubernetes.io/master=:NoSchedule --overwrite"
  delegate_to: "{{ groups['master'][0] }}"
  run_once: true
  with_items:
    - "{{ groups['master'] }}"

- name: "Create label for master"
  shell: "kubectl label nodes {{ hostvars[item].hostname }}-{{ item }} node-role.kubernetes.io/control-plane= node-role.kubernetes.io/master= --overwrite"
  delegate_to: "{{ groups['master'][0] }}"
  run_once: true
  with_items:
    - "{{ groups['master'] }}"

- name: "Create label for worker"
  shell: "kubectl label nodes {{ hostvars[item].hostname }}-{{ item }} node-role.kubernetes.io/worker= --overwrite"
  delegate_to: "{{ groups['master'][0] }}"
  run_once: true
  with_items:
    - "{{ groups['worker'] }}"
